# ğŸ§  Projet : DÃ©tection de fraude bancaire

**Auteur :** Mohamed Lamine OULD BOUYA  
**Objectif :** Concevoir un modÃ¨le de classification capable dâ€™identifier les transactions frauduleuses avec un **haut rappel** et une **bonne prÃ©cision-rappel (PR-AUC)**, malgrÃ© un **dÃ©sÃ©quilibre extrÃªme** entre transactions normales et frauduleuses.

---

## ğŸ“Š DonnÃ©es
- **Source :** [Kaggle - Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)
- **Taille :** 284 807 transactions, dont seulement **0.17 %** de fraudes

---

## âš™ï¸ Stack technique
- **Langage :** Python  
- **Librairies :** `pandas`, `scikit-learn`, `imbalanced-learn`, `xgboost`, `matplotlib`, `seaborn`  

---

## ğŸ§© MÃ©thodologie
- **PrÃ©traitement :**
  - Standardisation des variables
  - Gestion du dÃ©sÃ©quilibre via **SMOTE**  
- **Validation :**
  - DÃ©coupage **stratifiÃ© (80/20)** pour le train/test
  - **Cross-validation (CV) stratifiÃ©e** pour lâ€™optimisation
- **Optimisation :**
  - **GridSearchCV** appliquÃ© Ã  la **Logistic Regression** (pÃ©nalitÃ©s, rÃ©gularisation)
  - Recherche du **seuil optimal FÎ² (Î²=2)** pour maximiser le rappel pondÃ©rÃ©

---

## ğŸ“ˆ Ã‰valuation
- **MÃ©triques principales :**
  - PR-AUC (*Average Precision*)  
  - ROC-AUC  
  - **Rappel**, **PrÃ©cision**, **F1-score**  
  - Matrice de confusion
- **Comparaison de modÃ¨les :**
  - Logistic Regression *(baseline & optimisÃ©e)*  
  - RandomForest  
  - XGBoost
- **CritÃ¨re de sÃ©lection :**
  - Meilleure balance **prÃ©cision / rappel**
  - Performances Ã©valuÃ©es sur **donnÃ©es test indÃ©pendantes**

---

## ğŸ’¾ Sorties et artefacts
- **Figures :** courbes PR et ROC, matrices de confusion, importances des features  
- **Fichiers sauvegardÃ©s :**
  - `reports/metrics.json` â€” performances comparatives des modÃ¨les  
  - `reports/figures/` â€” figures PR, ROC, importances, matrices de confusion  
  - `train_split.csv` / `test_split.csv` â€” Ã©chantillons dâ€™entraÃ®nement et de test  

---

## ğŸš€ RÃ©sumÃ©
Ce projet illustre la construction complÃ¨te dâ€™un pipeline de dÃ©tection de fraude, de la prÃ©paration des donnÃ©es jusquâ€™Ã  lâ€™Ã©valuation des modÃ¨les, en appliquant les **bonnes pratiques de Machine Learning** (validation croisÃ©e, seuil optimal, gestion du dÃ©sÃ©quilibre, export des artefacts).  
Les rÃ©sultats montrent une amÃ©lioration significative du **PR-AUC** et du **rappel** grÃ¢ce Ã  lâ€™optimisation des modÃ¨les et Ã  lâ€™intÃ©gration de techniques de rÃ©Ã©chantillonnage.

---

## ğŸ“Š RÃ©sultats comparatifs

| ModÃ¨le | PR-AUC | ROC-AUC | PrÃ©cision | Rappel | F1-score | Seuil |
|:--|--:|--:|--:|--:|--:|--:|
| LR + SMOTE (grid) | 0.7197 | 0.9708 | 0.7961 | 0.8367 | 0.8159 | 1.000 |
| RandomForest | 0.8623 | 0.9515 | 0.8349 | 0.8776 | 0.8557 | 0.170 |
| XGBoost | 0.8741 | 0.9563 | 0.8492 | 0.8830 | 0.8657 | 0.150 |



